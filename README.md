# üìä **Projeto de Classifica√ß√£o de Textos com Modelos de Machine Learning**

Este projeto utiliza tr√™s modelos de **Machine Learning** - `Naive Bayes`, `Regress√£o Log√≠stica` e `Random Forest` - para realizar a classifica√ß√£o de textos em um conjunto de dados de **tweets**. O objetivo √© comparar a capacidade desses modelos em identificar padr√µes nos textos e fornecer previs√µes precisas.

---

## üéØ **Objetivo**
- Utilizar **Naive Bayes**, **Logistic Regression**, e **Random Forest** para realizar a classifica√ß√£o de textos.
- Avaliar o desempenho de cada modelo utilizando m√©tricas adequadas, como acur√°cia, precis√£o, revoca√ß√£o e F1-score.
- Demonstrar o uso de diferentes pipelines de pr√©-processamento (`text_basic`, `text_spacy`, `text_nltk`) para a prepara√ß√£o dos dados.

---

## üõ† **Tecnologias e Ferramentas Usadas**
- **Linguagem:** Python
- **Bibliotecas:**
  - `pandas`: Para manipula√ß√£o e prepara√ß√£o dos dados.
  - `scikit-learn`: Para modelagem de Machine Learning, m√©tricas de avalia√ß√£o e pr√©-processamento.
  - `spacy` e `nltk`: Para pr√©-processamento dos textos.
  - `Matplotlib`: Para visualiza√ß√£o dos resultados (opcional).

---

## üìÇ **Estrutura do Projeto**
### **Arquivos e Diret√≥rios**
- **`text_classification_project.ipynb`**: Notebook principal contendo:
  - Prepara√ß√£o e limpeza dos dados.
  - Treinamento dos modelos **Naive Bayes**, **Logistic Regression**, e **Random Forest**.
  - Compara√ß√£o entre os tr√™s modelos.
  - Visualiza√ß√£o dos resultados e m√©tricas de desempenho.

---

## üß† **Modelos Implementados**
- **Naive Bayes:**
  - Modelo probabil√≠stico que assume independ√™ncia entre as caracter√≠sticas e √© muito eficiente para problemas de classifica√ß√£o de texto.

- **Logistic Regression:**
  - Modelo linear que realiza a classifica√ß√£o usando uma fun√ß√£o sigmoide, √∫til para detec√ß√£o de padr√µes lineares nos dados.

- **Random Forest:**
  - Conjunto de √°rvores de decis√£o que realiza classifica√ß√µes robustas e melhora a precis√£o reduzindo o overfitting.

---

## üöÄ **Pr√≥ximos Passos**
- Testar os modelos com outros conjuntos de dados para verificar a generaliza√ß√£o.
- **Ajustar Hiperpar√¢metros** dos Modelos:
  - Explorar t√©cnicas como `GridSearchCV` ou `RandomizedSearchCV` para encontrar melhores par√¢metros.
- **Equilibrar as Classes**:
  - Usar t√©cnicas de balanceamento, como `SMOTE`, para melhorar a classifica√ß√£o de classes minorit√°rias.
- **Dashboard Interativo**:
  - Desenvolver um dashboard utilizando **Streamlit** ou **Dash** para exibir as previs√µes e m√©tricas de forma interativa.

---

## üìä **Sugest√µes de Aperfei√ßoamento**
1. **Normaliza√ß√£o dos Dados:** Utilize escaladores como `StandardScaler` ou `MinMaxScaler` para garantir que os dados estejam na mesma escala, melhorando o desempenho dos modelos.
2. **Valida√ß√£o Cruzada:** Implementar uma t√©cnica como **Stratified K-Fold** para uma valida√ß√£o mais robusta e confi√°vel.
3. **Visualiza√ß√£o das M√©tricas:** Adicionar gr√°ficos de barras para compara√ß√£o visual das m√©tricas de desempenho entre os modelos e as classes.
4. **Implementa√ß√£o de Modelos Adicionais:** Testar modelos como `SVM` ou `Gradient Boosting` para enriquecer a an√°lise comparativa.
5. **Otimiza√ß√£o de Pipeline:** Automatizar o pr√©-processamento e a modelagem com **Pipeline** do `scikit-learn` para facilitar a reprodutibilidade.

---

## üìù **Licen√ßa**
Este projeto √© licenciado sob a [Licen√ßa MIT](LICENSE).

---

## üë§ **Autor**
Guilherme Koiti Tanaka Sassaki  
[LinkedIn](https://www.linkedin.com/in/guilherme-sassaki-10b81ba7/)

