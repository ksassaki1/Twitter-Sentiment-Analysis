# üìä **Projeto de Classifica√ß√£o de Textos com Modelos de Machine Learning**

Este projeto utiliza tr√™s modelos de **Machine Learning** - `Naive Bayes`, `Regress√£o Log√≠stica` e `Random Forest` - para realizar a classifica√ß√£o de textos em um conjunto de dados de **tweets**. O objetivo √© comparar a capacidade desses modelos em identificar padr√µes nos textos e fornecer previs√µes precisas.

---

## üéØ **Objetivo**
- Utilizar **Naive Bayes**, **Logistic Regression**, e **Random Forest** para realizar a classifica√ß√£o de textos.
- Avaliar o desempenho de cada modelo utilizando m√©tricas adequadas, como acur√°cia, precis√£o, revoca√ß√£o e F1-score.
- Demonstrar o uso de diferentes pipelines de pr√©-processamento (`text_basic`, `text_spacy`, `text_nltk`) para a prepara√ß√£o dos dados.

---

## üõ† **Tecnologias e Ferramentas Usadas**
- **Linguagem:** Python
- **Bibliotecas:**
  - `pandas`: Para manipula√ß√£o e prepara√ß√£o dos dados.
  - `scikit-learn`: Para modelagem de Machine Learning, m√©tricas de avalia√ß√£o e pr√©-processamento.
  - `spacy` e `nltk`: Para pr√©-processamento dos textos.
  - `Matplotlib`: Para visualiza√ß√£o dos resultados (opcional).

---

## üìÇ **Estrutura do Projeto**
### **Arquivos e Diret√≥rios**
- **`text_classification_project.ipynb`**: Notebook principal contendo:
  - Prepara√ß√£o e limpeza dos dados.
  - Nuvem de palavras mais comuns positivas e negativas de pr√©-processamento NLP.
  - Treinamento dos modelos **Naive Bayes**, **Logistic Regression**, e **Random Forest**.
  - Compara√ß√£o entre os tr√™s modelos.
  - Visualiza√ß√£o dos resultados e m√©tricas de desempenho.

---

## üß† **Modelos Implementados**
- **Naive Bayes:**
  - Modelo probabil√≠stico que assume independ√™ncia entre as caracter√≠sticas e √© muito eficiente para problemas de classifica√ß√£o de texto.

- **Logistic Regression:**
  - Modelo linear que realiza a classifica√ß√£o usando uma fun√ß√£o sigmoide, √∫til para detec√ß√£o de padr√µes lineares nos dados.

- **Random Forest:**
  - Conjunto de √°rvores de decis√£o que realiza classifica√ß√µes robustas e melhora a precis√£o reduzindo o overfitting.

- **Pipelines de Pr√©-Processamento NLP:**
  - **text_basic:** Realiza uma limpeza b√°sica dos textos, removendo URLs, men√ß√µes e caracteres especiais, √∫til para uma abordagem simples de pr√©-processamento.
  - **text_spacy:** Utiliza a biblioteca spaCy para lematiza√ß√£o e remo√ß√£o de stopwords, permitindo uma an√°lise mais profunda e refinada dos textos.
  - **text_nltk:** Utiliza a biblioteca NLTK para tokeniza√ß√£o e lematiza√ß√£o, sendo uma alternativa ao spaCy para processamento de linguagem natural.

---

## üìä **Resultados Encontrados**
Durante os experimentos, os tr√™s modelos foram avaliados utilizando os diferentes pipelines de pr√©-processamento (`text_basic`, `text_spacy`, `text_nltk`). Aqui est√£o os principais resultados encontrados:

- **Pipeline `text_basic`**:
  - **Logistic Regression** apresentou o melhor desempenho, com uma acur√°cia de **78%**, seguido por `Naive Bayes` e `Random Forest` ambos com acur√°cia de **76%**.

- **Pipeline `text_spacy`**:
  - **Logistic Regression** tamb√©m foi o melhor modelo, com uma acur√°cia de **75%**, enquanto `Naive Bayes` e `Random Forest` obtiveram acur√°cias de **74%**.

- **Pipeline `text_nltk`**:
  - **Logistic Regression** mais uma vez se destacou, alcan√ßando uma acur√°cia de **76%**, enquanto `Naive Bayes` e `Random Forest` obtiveram **75%**.

**Conclus√£o Geral**: O modelo **Logistic Regression** foi consistentemente o melhor entre os tr√™s, apresentando o desempenho mais robusto em todos os pipelines de pr√©-processamento. O pipeline `text_basic` teve um desempenho ligeiramente superior em compara√ß√£o aos outros m√©todos de pr√©-processamento.

---

## üöÄ **Pr√≥ximos Passos**
- Testar os modelos com outros conjuntos de dados para verificar a generaliza√ß√£o.
- **Ajustar Hiperpar√¢metros** dos Modelos:
  - Explorar t√©cnicas como `GridSearchCV` ou `RandomizedSearchCV` para encontrar melhores par√¢metros.
- **Equilibrar as Classes**:
  - Usar t√©cnicas de balanceamento, como `SMOTE`, para melhorar a classifica√ß√£o de classes minorit√°rias.
- **Dashboard Interativo**:
  - Desenvolver um dashboard utilizando **Streamlit** ou **Dash** para exibir as previs√µes e m√©tricas de forma interativa.

---

## üìä **Base de Dados Utilizada**
Este projeto utilizou a base de dados [Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140), que cont√©m 1,6 milh√µes de tweets rotulados para an√°lise de sentimento.
- As classes foram rotuladas como `0` para sentimentos **negativos** e `4` para sentimentos **positivos**.

---

## üìù **Licen√ßa**
Este projeto √© licenciado sob a [Licen√ßa MIT](LICENSE).

---

## üë§ **Autor**
Guilherme Koiti Tanaka Sassaki  
[LinkedIn](https://www.linkedin.com/in/guilherme-sassaki-10b81ba7/)


