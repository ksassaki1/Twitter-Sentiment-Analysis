# üìä **Projeto de Classifica√ß√£o de Textos com NLP**

Este projeto utiliza tr√™s modelos de **Machine Learning** - `Naive Bayes`, `Regress√£o Log√≠stica` e `Random Forest` - para realizar a classifica√ß√£o de textos em um conjunto de dados de **tweets**. O objetivo √© comparar a capacidade desses modelos em identificar padr√µes nos textos e fornecer previs√µes se o texto apresenta um sentimento positivo ou negativo.

---

## üéØ **Objetivo**
- Utilizar **Naive Bayes**, **Logistic Regression**, e **Random Forest** para realizar a classifica√ß√£o de textos em sentimentos positivos ou negativos.
- Avaliar o desempenho de cada modelo utilizando m√©tricas adequadas, como acur√°cia, precis√£o, revoca√ß√£o e F1-score.
- Demonstrar o uso de diferentes pipelines de pr√©-processamento (`text_basic`, `text_spacy`, `text_nltk`) para a prepara√ß√£o dos dados.

---

## üõ† **Tecnologias e Ferramentas Usadas**
- **Linguagem:** Python
- **Bibliotecas:**
  - `pandas`: Para manipula√ß√£o e prepara√ß√£o dos dados.
  - `scikit-learn`: Para modelagem de Machine Learning, m√©tricas de avalia√ß√£o e pr√©-processamento.
  - `spacy` e `nltk`: Para pr√©-processamento dos textos.
  - `Matplotlib`: Para visualiza√ß√£o dos resultados (opcional).

---

## üìÇ **Estrutura do Projeto**
### **Arquivos e Diret√≥rios**
- **`text_classification_project.ipynb`**: Notebook principal contendo:
  - Prepara√ß√£o e limpeza dos dados.
  - Nuvem de palavras mais comuns separadas por positivas e negativas e por pr√©-processamento NLP.
  - Treinamento dos modelos **Naive Bayes**, **Logistic Regression**, e **Random Forest**.
  - Visualiza√ß√£o dos resultados e m√©tricas de desempenho.

## üìä **Nuvem de Palavras**
Abaixo est√£o exemplos de nuvens de palavras geradas a partir dos tweets classificados como positivos e negativos:

### Nuvem de Palavras - Sentimento Positivo
![Nuvem de Palavras - Sentimento Positivo]([image](https://github.com/user-attachments/assets/4e29bbfa-5caf-4c43-87b4-1d4214089194)
)

### Nuvem de Palavras - Sentimento Negativo
![Nuvem de Palavras - Sentimento Negativo]([image](https://github.com/user-attachments/assets/8d8d168b-26b9-4bbf-9df3-ec81e33e09af)
)

---

## üß† **Modelos Implementados**
- **Naive Bayes:**
  - Modelo probabil√≠stico que assume independ√™ncia entre as caracter√≠sticas e √© muito eficiente para problemas de classifica√ß√£o de texto.

- **Logistic Regression:**
  - Modelo linear que realiza a classifica√ß√£o usando uma fun√ß√£o sigmoide, √∫til para detec√ß√£o de padr√µes lineares nos dados.

- **Random Forest:**
  - Conjunto de √°rvores de decis√£o que realiza classifica√ß√µes robustas e melhora a precis√£o reduzindo o overfitting.

- **Pipelines de Pr√©-Processamento NLP:**
  - **text_basic:** Realiza uma limpeza b√°sica dos textos, removendo URLs, men√ß√µes e caracteres especiais, √∫til para uma abordagem simples de pr√©-processamento.
  - **text_spacy:** Utiliza a biblioteca spaCy para lematiza√ß√£o e remo√ß√£o de stopwords, permitindo uma an√°lise mais profunda e refinada dos textos.
  - **text_nltk:** Utiliza a biblioteca NLTK para tokeniza√ß√£o e lematiza√ß√£o, sendo uma alternativa ao spaCy para processamento de linguagem natural.

**Nota sobre NLP**: O processamento de linguagem natural (NLP) √© uma etapa fundamental para preparar os textos de forma que possam ser usados pelos modelos de Machine Learning. Neste projeto, foram utilizados diferentes m√©todos de NLP para avaliar qual t√©cnica de pr√©-processamento forneceria melhores resultados na classifica√ß√£o de sentimentos dos tweets.

---

## üìä **Resultados Encontrados**
Durante os experimentos, os tr√™s modelos foram avaliados utilizando os diferentes pipelines de pr√©-processamento (`text_basic`, `text_spacy`, `text_nltk`). Aqui est√£o os principais resultados encontrados:

- **Pipeline `text_basic`**:
  - **Logistic Regression** apresentou o melhor desempenho, com uma acur√°cia de **78%**, seguido por `Naive Bayes` e `Random Forest` ambos com acur√°cia de **76%**.

- **Pipeline `text_spacy`**:
  - **Logistic Regression** tamb√©m foi o melhor modelo, com uma acur√°cia de **75%**, enquanto `Naive Bayes` e `Random Forest` obtiveram acur√°cias de **74%**.

- **Pipeline `text_nltk`**:
  - **Logistic Regression** mais uma vez se destacou, alcan√ßando uma acur√°cia de **76%**, enquanto `Naive Bayes` e `Random Forest` obtiveram **75%**.

**Conclus√£o Geral**: O modelo **Logistic Regression** foi consistentemente o melhor entre os tr√™s, apresentando o desempenho mais robusto em todos os pipelines de pr√©-processamento. O pipeline `text_basic` teve um desempenho ligeiramente superior em compara√ß√£o aos outros m√©todos de pr√©-processamento.

---

## üöÄ **Pr√≥ximos Passos**
- Testar os modelos com outros conjuntos de dados para verificar a generaliza√ß√£o.
- **Ajustar Hiperpar√¢metros** dos Modelos:
  - Explorar t√©cnicas como `GridSearchCV` ou `RandomizedSearchCV` para encontrar melhores par√¢metros.
- **Dashboard Interativo**:
  - Desenvolver um dashboard utilizando **Streamlit** ou **Dash** para exibir as previs√µes e m√©tricas de forma interativa.

---

## üìä **Base de Dados Utilizada**
Este projeto utilizou a base de dados [Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140), que cont√©m 1,6 milh√µes de tweets rotulados para an√°lise de sentimento.

### **Contexto**
Este √© o dataset Sentiment140, que cont√©m 1.600.000 tweets extra√≠dos utilizando a API do Twitter. Os tweets foram anotados para indicar o sentimento:
- `0` = Sentimento **negativo**
- `4` = Sentimento **positivo`

### **Estrutura dos Dados**
O dataset cont√©m os seguintes 6 campos:
- **target**: Polaridade do tweet (`0` = negativo, `2` = neutro, `4` = positivo)
- **ids**: Identificador do tweet (exemplo: `2087`)
- **date**: Data do tweet (exemplo: `Sat May 16 23:58:44 UTC 2009`)
- **flag**: Consulta realizada (`lyx`). Se n√£o houver consulta, o valor √© `NO_QUERY`
- **user**: Usu√°rio que fez o tweet (exemplo: `robotickilldozr`)
- **text**: Texto do tweet (exemplo: `"Lyx is cool"`)

Neste projeto, foram utilizadas apenas as classes `0` (negativo) e `4` (positivo) para a classifica√ß√£o de sentimentos.

---

## üë§ **Autor**
Guilherme Koiti Tanaka Sassaki  
[LinkedIn](https://www.linkedin.com/in/guilherme-sassaki-10b81ba7/)

